{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "04-04-2021-task1-b-MultiChannel.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "p4mWLIENL2MW",
        "DnZbZFBqMGFX"
      ],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyM0V2MZ9vYvvtVoXHgngu9P",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohamedtal/PFE2021/blob/main/04_04_2021_task1_b_MultiChannel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOStV2j0z6O6"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "from tensorflow.keras.applications.densenet import DenseNet121\n",
        "from tensorflow.python.keras import Model\n",
        "from tensorflow.python.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras import layers\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.applications import DenseNet121\n",
        "from keras.utils import Sequence\n",
        "from keras.layers import Dense, Dropout, Flatten, Input, ZeroPadding2D, GlobalAveragePooling2D\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras import regularizers\n",
        "from keras.models import Model\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from keras import optimizers\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import backend as K\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "from pickle import load\n",
        "from numpy import array\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras.layers import Embedding\n",
        "from keras.layers.merge import concatenate\n",
        "from tensorflow.keras.layers import AvgPool2D, GlobalAveragePooling2D, MaxPool2D\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Dense\n",
        "from tensorflow.keras.layers import AvgPool2D, GlobalAveragePooling2D, MaxPool2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import ReLU, concatenate\n",
        "import tensorflow.keras.backend as K\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iu3j6LSaPwJw",
        "outputId": "c145be41-7354-4f7b-d78e-d392b57d28a0"
      },
      "source": [
        "# before all don't forget to use the GPU\n",
        "\n",
        "# at first we need to get the dataset from the drive \n",
        "# pfe2021.1@gmail.com\t\tzakimoha123\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWFnpMp1Q5mg"
      },
      "source": [
        "#unzip the dataset\n",
        "\n",
        "# for the train\n",
        "!unzip /content/drive/MyDrive/dataset/task1-batches/batchesTrain.zip\n",
        "!unzip /content/drive/MyDrive/dataset/task1-batches/batchesTest.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJRYwQ4IWMev"
      },
      "source": [
        "# read data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NK806shyWOxw"
      },
      "source": [
        "# read images \n",
        "path_train = 'batchesTrain/'\n",
        "list_batches = []\n",
        "for i in range(1,17):\n",
        "  path_batch = path_train+str(i)\n",
        "  batch_images = []\n",
        "  for c in range(5):\n",
        "    path_class = path_batch+'/'+str(c)\n",
        "    # get the list of images in each class\n",
        "    list_images =  os.listdir(path_class)\n",
        "    i = 0\n",
        "    for image in list_images :\n",
        "      path_image = path_class+'/'+image\n",
        "      img = cv2.imread(path_image)\n",
        "      img = cv2.resize(img,(224,224))\n",
        "      batch_images.append(img)\n",
        "      if i>=300:\n",
        "        break\n",
        "      i = i+1\n",
        "  list_batches.append(np.array(batch_images))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1jPkkK8es4b"
      },
      "source": [
        "# read labels\n",
        "path = 'batchesTrain/1/'\n",
        "trainY = []\n",
        "for c in range(5):\n",
        "  y = np.zeros(5,dtype=int)\n",
        "  y[c] = 1\n",
        "  path_class = path+str(c)\n",
        "  # get the list of images in each class\n",
        "  list_images =  os.listdir(path_class)\n",
        "  i = 0\n",
        "  for image in list_images :\n",
        "    trainY.append(y)\n",
        "    if i>=300:\n",
        "        break\n",
        "    i = i+1\n",
        "trainY = np.array(trainY)\n",
        "# convert to numpy array"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2KkOcr2i6v0"
      },
      "source": [
        "# read images \n",
        "path_test = 'batchesTest/'\n",
        "list_batches_test = []\n",
        "for i in range(1,17):\n",
        "  path_batch = path_test+str(i)\n",
        "  batch_images = []\n",
        "  for c in range(5):\n",
        "    path_class = path_batch+'/'+str(c)\n",
        "    # get the list of images in each class\n",
        "    list_images =  os.listdir(path_class)\n",
        "    for image in list_images :\n",
        "      path_image = path_class+'/'+image\n",
        "      img = cv2.imread(path_image)\n",
        "      img = cv2.resize(img,(224,224))\n",
        "      batch_images.append(img)\n",
        "  list_batches_test.append(np.array(batch_images))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9H9alaTRi6v2"
      },
      "source": [
        "# read labels\n",
        "path = 'batchesTest/1/'\n",
        "trainY_test = []\n",
        "for c in range(5):\n",
        "  y = np.zeros(5,dtype=int)\n",
        "  y[c] = 1\n",
        "  path_class = path+str(c)\n",
        "  # get the list of images in each class\n",
        "  list_images =  os.listdir(path_class)\n",
        "  for image in list_images :\n",
        "    trainY_test.append(y)\n",
        "trainY_test = np.array(trainY_test)\n",
        "# convert to numpy array"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KgkolVhvg9pV",
        "outputId": "6d7a4947-9709-4cbc-9e42-3b218b5fd65f"
      },
      "source": [
        "print(trainY_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(500, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4mWLIENL2MW"
      },
      "source": [
        "# data preprocessing\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75kOsJ9balEO"
      },
      "source": [
        "def preprocessFunction(image):\n",
        "    #image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
        "    kopya = image.copy()\n",
        "    kopya = cv2.cvtColor(kopya,cv2.COLOR_RGB2GRAY)\n",
        "    blur = cv2.GaussianBlur(kopya,(5,5),0)\n",
        "    thresh = cv2.threshold(blur,10,255,cv2.THRESH_BINARY)[1]\n",
        "    kontur = cv2.findContours(thresh.copy(),cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
        "    kontur = kontur[0][0]\n",
        "    kontur = kontur[:,0,:]\n",
        "    x1 = tuple(kontur[kontur[:,0].argmin()])[0]\n",
        "    x2 = tuple(kontur[kontur[:,0].argmax()])[0]\n",
        "    y1 = tuple(kontur[kontur[:,1].argmin()])[1]\n",
        "    y2 = tuple(kontur[kontur[:,1].argmax()])[1]\n",
        "    x = int(x2-x1)*4//50\n",
        "    y = int(y2-y1)*5//50\n",
        "    kopya2 = image.copy()\n",
        "    if x2-x1>100 and y2-y1>100 :\n",
        "        kopya2 = kopya2[y1+y:y2-y , x1+x:x2-x]\n",
        "        kopya2 = cv2.resize(kopya2,(1024,1024))\n",
        "    lab = cv2.cvtColor(kopya2,cv2.COLOR_RGB2LAB)\n",
        "    l,a,b = cv2.split(lab)\n",
        "    clahe = cv2.createCLAHE(clipLimit=5.0,tileGridSize=((8,8)))\n",
        "    cl = clahe.apply(l)\n",
        "    limg = cv2.merge((cl,a,b))\n",
        "    son = cv2.cvtColor(limg,cv2.COLOR_LAB2RGB)\n",
        "    med_son = cv2.medianBlur(son,3)\n",
        "    arka_plan = cv2.medianBlur(son,37)\n",
        "    maske = cv2.addWeighted(med_son,1,arka_plan,-1,255)\n",
        "    son_img = cv2.bitwise_and(maske,med_son)\n",
        "    return son_img\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FcJm4yiCT6_l",
        "outputId": "2fbb165d-739a-4f5d-eb84-78716bcf05f4"
      },
      "source": [
        "#read images, do division, save results batches\n",
        "path = 'DR-dataset/train/'\n",
        "numberTrainImagesPerClass = 600\n",
        "numberTestImagesPerClass = 100\n",
        "size_batch = 255\n",
        "sizeOfOriginalImage = 1024\n",
        "numberOfClass = 5\n",
        "\n",
        "def createBatches(path,numberTrainImagesPerClass,numberTestImagesPerClass,size_batch,sizeOfOriginalImage,numberOfClass):\n",
        "    numberOfBatch = sizeOfOriginalImage // size_batch\n",
        "    trainX = np.array([3000,16,255,255,3], np.int8)\n",
        "    trainY = np.array([3000,1])\n",
        "    l = 0\n",
        "    for c in range(numberOfClass):\n",
        "      # the path of each class\n",
        "      path_class = path + str(c)\n",
        "      # get the list of images in each class\n",
        "      list_images =  os.listdir(path_class)\n",
        "      # choose randomly 300 images from the previous list\n",
        "      choosed_images = random.sample(list_images, numberTrainImagesPerClass+numberTestImagesPerClass)\n",
        "      # get train dataset\n",
        "      for k in range(numberTrainImagesPerClass):\n",
        "        # get the path of each image\n",
        "        image = choosed_images[k]\n",
        "        path_image = path_class+'/'+ image\n",
        "        # read the image\n",
        "        img = cv2.imread(path_image)\n",
        "        try:\n",
        "          img = preprocessFunction(img)\n",
        "        except:\n",
        "          pass\n",
        "        img = cv2.resize(img, dsize=(sizeOfOriginalImage, sizeOfOriginalImage))\n",
        "        numeroBatch = 1\n",
        "        m = 0\n",
        "        for i in range(numberOfBatch):\n",
        "          for j in range(numberOfBatch):\n",
        "            batch = img[i*size_batch:i*size_batch+size_batch,j*size_batch:j*size_batch+size_batch,:]\n",
        "            try:\n",
        "                trainX[l][m] = batch\n",
        "            except Exception as e:\n",
        "                print('error_train'+str(e))\n",
        "            m = m+1\n",
        "            numeroBatch = numeroBatch + 1\n",
        "        trainY[l] = c\n",
        "        l = l+1\n",
        "createBatches(path,numberTrainImagesPerClass,numberTestImagesPerClass,size_batch,sizeOfOriginalImage,numberOfClass)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "error_train'numpy.int8' object does not support item assignment\n",
            "error_train'numpy.int8' object does not support item assignment\n",
            "error_train'numpy.int8' object does not support item assignment\n",
            "error_train'numpy.int8' object does not support item assignment\n",
            "error_train'numpy.int8' object does not support item assignment\n",
            "error_train'numpy.int8' object does not support item assignment\n",
            "error_train'numpy.int8' object does not support item assignment\n",
            "error_train'numpy.int8' object does not support item assignment\n",
            "error_train'numpy.int8' object does not support item assignment\n",
            "error_train'numpy.int8' object does not support item assignment\n",
            "error_train'numpy.int8' object does not support item assignment\n",
            "error_train'numpy.int8' object does not support item assignment\n",
            "error_train'numpy.int8' object does not support item assignment\n",
            "error_train'numpy.int8' object does not support item assignment\n",
            "error_train'numpy.int8' object does not support item assignment\n",
            "error_train'numpy.int8' object does not support item assignment\n",
            "error_train'numpy.int8' object does not support item assignment\n",
            "error_train'numpy.int8' object does not support item assignment\n",
            "error_train'numpy.int8' object does not support item assignment\n",
            "error_train'numpy.int8' object does not support item assignment\n",
            "error_train'numpy.int8' object does not support item assignment\n",
            "error_train'numpy.int8' object does not support item assignment\n",
            "error_train'numpy.int8' object does not support item assignment\n",
            "error_train'numpy.int8' object does not support item assignment\n",
            "error_train'numpy.int8' object does not support item assignment\n",
            "error_train'numpy.int8' object does not support item assignment\n",
            "error_train'numpy.int8' object does not support item assignment\n",
            "error_train'numpy.int8' object does not support item assignment\n",
            "error_train'numpy.int8' object does not support item assignment\n",
            "error_train'numpy.int8' object does not support item assignment\n",
            "error_train'numpy.int8' object does not support item assignment\n",
            "error_train'numpy.int8' object does not support item assignment\n",
            "error_train'numpy.int8' object does not support item assignment\n",
            "error_train'numpy.int8' object does not support item assignment\n",
            "error_train'numpy.int8' object does not support item assignment\n",
            "error_train'numpy.int8' object does not support item assignment\n",
            "error_train'numpy.int8' object does not support item assignment\n",
            "error_train'numpy.int8' object does not support item assignment\n",
            "error_train'numpy.int8' object does not support item assignment\n",
            "error_train'numpy.int8' object does not support item assignment\n",
            "error_train'numpy.int8' object does not support item assignment\n",
            "error_train'numpy.int8' object does not support item assignment\n",
            "error_train'numpy.int8' object does not support item assignment\n",
            "error_train'numpy.int8' object does not support item assignment\n",
            "error_train'numpy.int8' object does not support item assignment\n",
            "error_train'numpy.int8' object does not support item assignment\n",
            "error_train'numpy.int8' object does not support item assignment\n",
            "error_train'numpy.int8' object does not support item assignment\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-75ca33a2d840>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mtrainY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0mcreateBatches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnumberTrainImagesPerClass\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnumberTestImagesPerClass\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msize_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msizeOfOriginalImage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnumberOfClass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-11-75ca33a2d840>\u001b[0m in \u001b[0;36mcreateBatches\u001b[0;34m(path, numberTrainImagesPerClass, numberTestImagesPerClass, size_batch, sizeOfOriginalImage, numberOfClass)\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mnumeroBatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumeroBatch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mtrainY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0mcreateBatches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnumberTrainImagesPerClass\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnumberTestImagesPerClass\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msize_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msizeOfOriginalImage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnumberOfClass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 2 is out of bounds for axis 0 with size 2"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sP0T-BoBJm2_"
      },
      "source": [
        "# creating the batches folder\n",
        "path_batch_train = 'batchesTrain'\n",
        "path_batch_test = 'batchesTest'\n",
        "\n",
        "def createBatchFolder(pathName):\n",
        "    try:\n",
        "        os.mkdir(pathName)\n",
        "    except OSError:\n",
        "        print (\"Creation of the directory %s failed\" % pathName)\n",
        "    else:\n",
        "        print (\"Successfully created the directory %s \" % pathName)\n",
        "    finally:\n",
        "        for i in range(1,17):\n",
        "          try:\n",
        "              pathBatch = pathName+'/'+str(i)\n",
        "              os.mkdir(pathBatch)\n",
        "          except OSError:\n",
        "              print (\"Creation of the directory %s failed\" % pathName)\n",
        "          finally:\n",
        "            for j in range(5):\n",
        "              try:\n",
        "                  pathClass = pathBatch+'/'+ str(j)\n",
        "                  os.mkdir(pathClass)\n",
        "              except OSError:\n",
        "                  print (\"Creation of the directory %s failed\" % pathName)\n",
        "# call the create path function\n",
        "createBatchFolder(path_batch_train)\n",
        "createBatchFolder(path_batch_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxkTuEO7Jqos"
      },
      "source": [
        "#read images, do division, save results batches\n",
        "path = 'DR-dataset/train/'\n",
        "numberTrainImagesPerClass = 600\n",
        "numberTestImagesPerClass = 100\n",
        "size_batch = 255\n",
        "sizeOfOriginalImage = 1024\n",
        "numberOfClass = 5\n",
        "\n",
        "def createBatches(path,path_batch,path_test,numberTrainImagesPerClass,numberTestImagesPerClass,size_batch,sizeOfOriginalImage,numberOfClass):\n",
        "    numberOfBatch = sizeOfOriginalImage // size_batch\n",
        "    for c in range(numberOfClass):\n",
        "      # the path of each class\n",
        "      path_class = path + str(c)\n",
        "      # get the list of images in each class\n",
        "      list_images =  os.listdir(path_class)\n",
        "      # choose randomly 300 images from the previous list\n",
        "      choosed_images = random.sample(list_images, numberTrainImagesPerClass+numberTestImagesPerClass)\n",
        "      # get train dataset\n",
        "      for k in range(numberTrainImagesPerClass):\n",
        "        # get the path of each image\n",
        "        image = choosed_images[k]\n",
        "        path_image = path_class+'/'+ image\n",
        "        # read the image\n",
        "        img = cv2.imread(path_image)\n",
        "        try:\n",
        "          img = preprocessFunction(img)\n",
        "        except:\n",
        "          pass\n",
        "        img = cv2.resize(img, dsize=(sizeOfOriginalImage, sizeOfOriginalImage))\n",
        "        numeroBatch = 1\n",
        "        for i in range(numberOfBatch):\n",
        "          for j in range(numberOfBatch):\n",
        "            batch = img[i*size_batch:i*size_batch+size_batch,j*size_batch:j*size_batch+size_batch,:]\n",
        "            try:\n",
        "                newPath = path_batch+'/'+str(numeroBatch)+'/'+str(c)+'/'+image\n",
        "                cv2.imwrite(newPath,batch)\n",
        "            except Exception as e:\n",
        "                print(img.shape)\n",
        "                print('error_train'+str(e))\n",
        "            numeroBatch = numeroBatch + 1\n",
        "      # get the test dataset\n",
        "      for k in range(numberTrainImagesPerClass,numberTrainImagesPerClass+numberTestImagesPerClass):\n",
        "        # get the path of each image\n",
        "        image = choosed_images[k]\n",
        "        path_image = path_class+'/'+image\n",
        "        # read the image\n",
        "        img = cv2.imread(path_image)\n",
        "        img = preprocessFunction(img)\n",
        "        img = cv2.resize(img, dsize=(sizeOfOriginalImage, sizeOfOriginalImage))\n",
        "        numeroBatch = 1\n",
        "        for i in range(numberOfBatch):\n",
        "          for j in range(numberOfBatch):\n",
        "            batch = img[i*size_batch:i*size_batch+size_batch,j*size_batch:j*size_batch+size_batch,:]\n",
        "            try:\n",
        "                newPath = path_test+'/'+str(numeroBatch)+'/'+str(c)+'/'+image\n",
        "                cv2.imwrite(newPath,batch)\n",
        "            except Exception as e: \n",
        "                print('error_test'+str(e))\n",
        "            numeroBatch = numeroBatch + 1\n",
        "\n",
        "createBatches(path,path_batch_train,path_batch_test,numberTrainImagesPerClass,numberTestImagesPerClass,size_batch,sizeOfOriginalImage,numberOfClass)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUXEHEFpK-_m"
      },
      "source": [
        "# augmenttaion\n",
        "import imageio\n",
        "import imgaug as ia\n",
        "import imgaug.augmenters as iaa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import matplotlib\n",
        "import os\n",
        "import cv2\n",
        "%matplotlib inline\n",
        "\n",
        "for i in range(1,17):\n",
        "  for j in range(5):\n",
        "    BASE_DIR = \"batchesTrain/\"+str(i)+'/'+str(j)\n",
        "    NEW_DIR= \"batchesTrain/\"+str(i)+'/'+str(j)\n",
        "    list_dir =  os.listdir(BASE_DIR)\n",
        "    from google.colab.patches import cv2_imshow\n",
        "    for images in list_dir:\n",
        "        image = cv2.imread(BASE_DIR + \"/\"+ images)\n",
        "        #image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
        "            \n",
        "        #rotation\n",
        "        rotate=iaa.Affine(rotate=(0, 30))\n",
        "        rotated_image=rotate.augment_image(image)\n",
        "        cv2.imwrite(NEW_DIR + \"/\" + 'rotated-'+images,rotated_image)\n",
        "\n",
        "        #zoom\n",
        "        crop = iaa.Crop(percent=(0.07, 0.12)) # crop image\n",
        "        corp_image=crop.augment_image(image)\n",
        "        cv2.imwrite(NEW_DIR + \"/\" + 'zoomed-'+images,corp_image)\n",
        "\n",
        "        #shear\n",
        "        crop = iaa.Affine(shear=10)\n",
        "        corp_image=crop.augment_image(image)\n",
        "        cv2.imwrite(NEW_DIR + \"/\" + 'affine-'+images,corp_image)\n",
        "\n",
        "        #flip H\n",
        "        flip_hr=iaa.Fliplr(p=1.0)\n",
        "        flip_hr_image= flip_hr.augment_image(image)\n",
        "        cv2.imwrite(NEW_DIR + \"/\" + 'fliph-'+images,flip_hr_image)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_w8Vtx505di"
      },
      "source": [
        "# create the Multi Channel Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iA7RlFKX0MWs"
      },
      "source": [
        "# create one channel\n",
        "def densenet(input_shape, filters = 32):  \n",
        "    #batch norm + relu + conv\n",
        "    def bn_rl_conv(x,filters,kernel=1,strides=1):\n",
        "        \n",
        "        x = BatchNormalization()(x)\n",
        "        x = ReLU()(x)\n",
        "        x = Conv2D(filters, kernel, strides=strides,padding = 'same')(x)\n",
        "        return x\n",
        "    \n",
        "    def dense_block(x, repetition):\n",
        "        \n",
        "        for _ in range(repetition):\n",
        "            y = bn_rl_conv(x, 4*filters)\n",
        "            y = bn_rl_conv(y, filters, 3)\n",
        "            x = concatenate([y,x])\n",
        "        return x\n",
        "        \n",
        "    def transition_layer(x):\n",
        "        \n",
        "        x = bn_rl_conv(x, K.int_shape(x)[-1] //2 )\n",
        "        x = AvgPool2D(2, strides = 2, padding = 'same')(x)\n",
        "        return x\n",
        "    \n",
        "    input = Input (input_shape)\n",
        "    x = Conv2D(64, 7, strides = 2, padding = 'same')(input)\n",
        "    x = MaxPool2D(3, strides = 2, padding = 'same')(x)\n",
        "    \n",
        "    for repetition in [6,12,24,16]:\n",
        "        \n",
        "        d = dense_block(x, repetition)\n",
        "        x = transition_layer(d)\n",
        "    x = GlobalAveragePooling2D()(d)\n",
        "    flat = Flatten()(x)\n",
        "    return flat,input\n",
        "\n",
        "  \n",
        "\n",
        "# define the model\n",
        "\n",
        "channels = []\n",
        "inputs = []\n",
        "for i in range(16):\n",
        "  channel,input =  densenet((224,224,3))\n",
        "  channels.append(channel)\n",
        "  inputs.append(input)\n",
        "# merge\n",
        "merged = concatenate([channels[0], channels[1], channels[2],channels[3], channels[4],channels[5],\n",
        "                      channels[6], channels[7], channels[8],channels[9], channels[10],\n",
        "                      channels[11],channels[12], channels[13], channels[14], channels[15]])\n",
        "\n",
        "outputs = Dense(5, activation='softmax')(merged)\n",
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "# compile\n",
        "model.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer=optimizers.Adam(lr=0.00005),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "# summarize\n",
        "#print(model.summary())\n",
        "#plot_model(model, show_shapes=True, to_file='multichannel.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DnZbZFBqMGFX"
      },
      "source": [
        "#Read data as Image Data Generator Object"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVSXTkO9IcLs"
      },
      "source": [
        "path_batch = 'batchesTrain'\n",
        "train_generators = []\n",
        "val_generators = []\n",
        "\n",
        "for i in range(1,17):\n",
        "  batchSize = 32\n",
        "  pathBatch = path_batch+'/'+str(i)+'/'\n",
        "  # ******** for train dataset\n",
        "\n",
        "  train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      validation_split=0.15\n",
        "      ) \n",
        "\n",
        "  train_generator = train_datagen.flow_from_directory(\n",
        "      pathBatch,\n",
        "      classes = ['0','1','2','3','4'],\n",
        "      target_size=(224, 224),\n",
        "      color_mode='rgb',\n",
        "      batch_size=batchSize,\n",
        "      class_mode='categorical',\n",
        "      subset='training',\n",
        "      shuffle=True)\n",
        "\n",
        "  # ******* for validation dataset\n",
        "  val_generator = train_datagen.flow_from_directory(\n",
        "      pathBatch,\n",
        "      classes = ['0','1','2','3','4'],\n",
        "      class_mode='categorical',\n",
        "      target_size=(224, 224),\n",
        "      color_mode='rgb',\n",
        "      subset='validation'\n",
        "  )\n",
        "  train_generators.append(train_generator)\n",
        "  val_generators.append(train_generator)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j33lFjaJOrgv"
      },
      "source": [
        "# start the training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cy8gp-uOh8j"
      },
      "source": [
        "earlystopper = EarlyStopping(\n",
        "            monitor = \"val_loss\",\n",
        "            mode=\"min\",\n",
        "            patience=10,\n",
        "            verbose=1\n",
        "  )\n",
        "model_checkpoint = ModelCheckpoint(\n",
        "              'drive/MyDrive/models/task-c/modelBatch'+str(i)+'.h5',\n",
        "              monitor='val_loss',\n",
        "              verbose=1,\n",
        "              save_best_only=True\n",
        "  )\n",
        "model.compile(optimizer=optimizers.Adam(lr=1e-5),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34YsY9AlbBrN",
        "outputId": "04b6c9ed-b6cf-4cb2-c2cd-85d1d6b0e0de"
      },
      "source": [
        "model.fit(list_batches, trainY, epochs=15, batch_size=4,validation_data=(list_batches_test,trainY_test),verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "377/377 [==============================] - 383s 1s/step - loss: 1.6114 - accuracy: 0.2930 - val_loss: 1.9128 - val_accuracy: 0.2260\n",
            "Epoch 2/15\n",
            "377/377 [==============================] - 341s 905ms/step - loss: 1.4925 - accuracy: 0.3528 - val_loss: 2.0004 - val_accuracy: 0.2720\n",
            "Epoch 3/15\n",
            "377/377 [==============================] - 341s 904ms/step - loss: 1.4440 - accuracy: 0.3960 - val_loss: 2.0699 - val_accuracy: 0.2800\n",
            "Epoch 4/15\n",
            "377/377 [==============================] - 340s 902ms/step - loss: 1.3788 - accuracy: 0.4279 - val_loss: 1.9888 - val_accuracy: 0.2860\n",
            "Epoch 5/15\n",
            "377/377 [==============================] - 339s 899ms/step - loss: 1.3842 - accuracy: 0.4146 - val_loss: 1.9450 - val_accuracy: 0.2740\n",
            "Epoch 6/15\n",
            "377/377 [==============================] - 339s 900ms/step - loss: 1.3085 - accuracy: 0.4598 - val_loss: 1.9543 - val_accuracy: 0.2980\n",
            "Epoch 7/15\n",
            "377/377 [==============================] - 339s 900ms/step - loss: 1.2697 - accuracy: 0.5010 - val_loss: 2.4693 - val_accuracy: 0.3000\n",
            "Epoch 8/15\n",
            "377/377 [==============================] - 339s 900ms/step - loss: 1.2432 - accuracy: 0.4837 - val_loss: 2.0258 - val_accuracy: 0.2900\n",
            "Epoch 9/15\n",
            "377/377 [==============================] - 340s 903ms/step - loss: 1.2076 - accuracy: 0.5130 - val_loss: 2.0087 - val_accuracy: 0.2960\n",
            "Epoch 10/15\n",
            "377/377 [==============================] - 340s 902ms/step - loss: 1.1935 - accuracy: 0.5236 - val_loss: 2.1304 - val_accuracy: 0.3080\n",
            "Epoch 11/15\n",
            "377/377 [==============================] - 339s 900ms/step - loss: 1.1604 - accuracy: 0.5422 - val_loss: 2.2205 - val_accuracy: 0.3020\n",
            "Epoch 12/15\n",
            "377/377 [==============================] - 339s 900ms/step - loss: 1.1253 - accuracy: 0.5395 - val_loss: 2.1451 - val_accuracy: 0.2740\n",
            "Epoch 13/15\n",
            "377/377 [==============================] - 339s 900ms/step - loss: 1.1247 - accuracy: 0.5548 - val_loss: 2.2552 - val_accuracy: 0.3260\n",
            "Epoch 14/15\n",
            "377/377 [==============================] - 340s 902ms/step - loss: 1.0723 - accuracy: 0.5880 - val_loss: 2.1495 - val_accuracy: 0.3160\n",
            "Epoch 15/15\n",
            "377/377 [==============================] - 340s 901ms/step - loss: 1.0377 - accuracy: 0.5841 - val_loss: 2.2763 - val_accuracy: 0.3000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc009575510>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXlCooYLQRiR"
      },
      "source": [
        "# drawing results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-40UcqqQMq4"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "#plt.plot(epochs, loss, 'g', label='Training loss')\n",
        "#plt.plot(epochs, val_loss, 'y', label='Validation loss')\n",
        "plt.title('Training and validation')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "plt.savefig('results/batch'+str(i)+'.png')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Th_CGGSQQaPJ"
      },
      "source": [
        "# evaluate using validation data"
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "04-01-2021-CNN-DataGenerator.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOJgWnQ0G1eJJpbx3i64Ak6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohamedtal/PFE2021/blob/main/04_01_2021_CNN_DataGenerator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J43LjEzPBEkk",
        "outputId": "44d76529-24ee-4598-b9e2-8b91a1c0b211"
      },
      "source": [
        "# before all don't forget to use the GPU\r\n",
        "\r\n",
        "# at first we need to get the dataset from the drive \r\n",
        "# pfe2021.1@gmail.com\t\tzakimoha123\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WL1HQdpZB7mN"
      },
      "source": [
        "#unzip the dataset\r\n",
        "\r\n",
        "# for the train\r\n",
        "!unzip /content/drive/MyDrive/dataset/DR-dataset2015.zip\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMv-xH29qi3m"
      },
      "source": [
        "# for the test\r\n",
        "!unzip /content/drive/MyDrive/dataset/DR-2019-test.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ajJUZBFKqov0",
        "outputId": "a8a47662-c7b1-44ad-c43b-e25581ec7d38"
      },
      "source": [
        "!ls DR-dataset/train/2  | wc -l"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5292\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GTEDUb3CSHy"
      },
      "source": [
        "# we need to delete samples from class 0 ( there is 25000 images, we are going to take just 7000)\r\n",
        "import random\r\n",
        "import os\r\n",
        "BASE_DIR = \"DR-dataset/train/0\"\r\n",
        "NEW_DIR= \"corbeille\"\r\n",
        "\r\n",
        "list_dir =  os.listdir(BASE_DIR)\r\n",
        "to_val = random.sample(list_dir, len(list_dir) - 7000)\r\n",
        "for images in to_val:\r\n",
        "    os.rename(BASE_DIR + \"/\"+ images, NEW_DIR + \"/\" + images )"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4N3xW0XNCw8w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "636c7508-3959-4110-fc36-d4f3d192e7a8"
      },
      "source": [
        "# we use the ImageDataGenerator fro : loading data into batches, pre-processing operation, data augmentation\r\n",
        "\r\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\r\n",
        "# the train generator with data augmentation and preprocessing (rescale)\r\n",
        "# https://xzz201920.medium.com/all-you-need-to-you-about-imagedatagenerator-in-keras-tensorflow-8fd436e4c0cd\r\n",
        "# https://medium.com/swlh/data-augmentation-using-keras-4a852e49589f\r\n",
        "# https://towardsdatascience.com/image-data-generators-in-keras-7c5fc6928400\r\n",
        "# https://keras.io/api/preprocessing/image/\r\n",
        "# https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator\r\n",
        "\r\n",
        "batchSize = 32\r\n",
        "\r\n",
        "# ******** for train dataset\r\n",
        "train_datagen = ImageDataGenerator(\r\n",
        "    rescale=1./255,\r\n",
        "    validation_split=0.15)\r\n",
        "\r\n",
        "train_generator = train_datagen.flow_from_directory(\r\n",
        "    'DR-dataset/train/',\r\n",
        "    classes = ['0','1','2','3','4'],\r\n",
        "    target_size=(224, 224),\r\n",
        "    color_mode='rgb',\r\n",
        "    batch_size=batchSize,\r\n",
        "    class_mode='categorical',\r\n",
        "    subset='training',\r\n",
        "    shuffle=True)\r\n",
        "\r\n",
        "# ******* for validation dataset\r\n",
        "val_generator = train_datagen.flow_from_directory(\r\n",
        "    'DR-dataset/train/',\r\n",
        "    classes = ['0','1','2','3','4'],\r\n",
        "    class_mode='categorical',\r\n",
        "    target_size=(224, 224),\r\n",
        "    color_mode='rgb',\r\n",
        "    subset='validation'\r\n",
        ")\r\n",
        "\r\n",
        "# ******** for test dataset\r\n",
        "\r\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\r\n",
        "test_generator = test_datagen.flow_from_directory(\r\n",
        "    'DR-dataset2019-test/test/',\r\n",
        "    classes = ['0','1','2','3','4'],\r\n",
        "    target_size=(224, 224),\r\n",
        "    class_mode='categorical',\r\n",
        "    color_mode='rgb',\r\n",
        "    batch_size = batchSize,\r\n",
        "    shuffle = False)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 13871 images belonging to 5 classes.\n",
            "Found 2445 images belonging to 5 classes.\n",
            "Found 3662 images belonging to 5 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NY0Gjypm1w8-"
      },
      "source": [
        "# transfer-learning  (resnet)\r\n",
        "\r\n",
        "num_classes = 5\r\n",
        "img_size = (224,224,3)\r\n",
        "\r\n",
        "# create the model\r\n",
        "from tensorflow.python.keras.applications.resnet import ResNet50\r\n",
        "from tensorflow.python.keras import Model\r\n",
        "from tensorflow.python.keras.layers import Dense, Flatten\r\n",
        "\r\n",
        "resnet = ResNet50(weights='imagenet', include_top=False, input_shape=img_size)\r\n",
        "\r\n",
        "x = Flatten(input_shape=resnet.output.shape)(resnet.output)\r\n",
        "x = Dense(1024, activation='sigmoid')(x)\r\n",
        "\r\n",
        "predictions = Dense(num_classes, activation='softmax', name='pred')(x)\r\n",
        "model = Model(inputs=[resnet.input], outputs=[predictions])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lDdeRfR4BlP"
      },
      "source": [
        "# compile the model and specify hyperparameters\r\n",
        "# https://medium.com/ml-cheat-sheet/winning-at-loss-functions-common-loss-functions-that-you-should-know-a72c1802ecb4\r\n",
        "# https://neptune.ai/blog/keras-loss-functions\r\n",
        "lossFunction = 'categorical_crossentropy'\r\n",
        "optimizeR = 'adam'\r\n",
        "model.compile(loss = lossFunction, optimizer=optimizeR, metrics=['accuracy'])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFpo3pg5EsGW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a067a4ff-6192-41b2-87b7-b5c9ca6ea92b"
      },
      "source": [
        "# start the train\r\n",
        "import math\r\n",
        "batchSize = 32\r\n",
        "history = model.fit_generator(\r\n",
        "    train_generator,\r\n",
        "    steps_per_epoch=math.ceil(train_generator.samples//batchSize),\r\n",
        "    epochs=50,\r\n",
        "    validation_data = val_generator,\r\n",
        "    validation_steps = math.ceil(val_generator.samples//batchSize),\r\n",
        "    verbose = 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "433/433 [==============================] - 281s 648ms/step - loss: 1.3409 - accuracy: 0.3977 - val_loss: 1.9450 - val_accuracy: 0.2722\n",
            "Epoch 2/50\n",
            "433/433 [==============================] - 277s 640ms/step - loss: 1.3359 - accuracy: 0.4067 - val_loss: 1.3613 - val_accuracy: 0.3302\n",
            "Epoch 3/50\n",
            "433/433 [==============================] - 277s 639ms/step - loss: 1.3364 - accuracy: 0.4003 - val_loss: 1.3355 - val_accuracy: 0.4293\n",
            "Epoch 4/50\n",
            "433/433 [==============================] - 275s 635ms/step - loss: 1.3317 - accuracy: 0.4043 - val_loss: 1.3136 - val_accuracy: 0.3976\n",
            "Epoch 5/50\n",
            "433/433 [==============================] - 275s 634ms/step - loss: 1.3361 - accuracy: 0.4074 - val_loss: 1.3261 - val_accuracy: 0.4408\n",
            "Epoch 6/50\n",
            "433/433 [==============================] - 274s 632ms/step - loss: 1.3392 - accuracy: 0.4055 - val_loss: 1.3354 - val_accuracy: 0.4264\n",
            "Epoch 7/50\n",
            "433/433 [==============================] - 274s 632ms/step - loss: 1.3331 - accuracy: 0.4069 - val_loss: 1.3218 - val_accuracy: 0.4248\n",
            "Epoch 8/50\n",
            "433/433 [==============================] - 273s 630ms/step - loss: 1.3314 - accuracy: 0.4166 - val_loss: 1.3246 - val_accuracy: 0.4305\n",
            "Epoch 9/50\n",
            "433/433 [==============================] - 274s 631ms/step - loss: 1.3255 - accuracy: 0.4166 - val_loss: 1.3317 - val_accuracy: 0.4293\n",
            "Epoch 10/50\n",
            "433/433 [==============================] - 275s 635ms/step - loss: 1.3277 - accuracy: 0.4107 - val_loss: 1.3562 - val_accuracy: 0.3692\n",
            "Epoch 11/50\n",
            "433/433 [==============================] - 275s 634ms/step - loss: 1.3318 - accuracy: 0.4101 - val_loss: 1.3079 - val_accuracy: 0.4322\n",
            "Epoch 12/50\n",
            "433/433 [==============================] - 276s 636ms/step - loss: 1.3234 - accuracy: 0.4151 - val_loss: 1.3312 - val_accuracy: 0.4248\n",
            "Epoch 13/50\n",
            "433/433 [==============================] - 274s 632ms/step - loss: 1.3180 - accuracy: 0.4232 - val_loss: 1.2947 - val_accuracy: 0.4433\n",
            "Epoch 14/50\n",
            "433/433 [==============================] - 273s 630ms/step - loss: 1.3122 - accuracy: 0.4285 - val_loss: 1.3210 - val_accuracy: 0.4317\n",
            "Epoch 15/50\n",
            "433/433 [==============================] - 273s 630ms/step - loss: 1.3251 - accuracy: 0.4248 - val_loss: 1.3012 - val_accuracy: 0.4313\n",
            "Epoch 16/50\n",
            "433/433 [==============================] - 273s 631ms/step - loss: 1.3127 - accuracy: 0.4234 - val_loss: 1.3256 - val_accuracy: 0.4404\n",
            "Epoch 17/50\n",
            "433/433 [==============================] - 272s 627ms/step - loss: 1.3133 - accuracy: 0.4293 - val_loss: 1.3279 - val_accuracy: 0.4478\n",
            "Epoch 18/50\n",
            "433/433 [==============================] - 272s 629ms/step - loss: 1.3390 - accuracy: 0.4128 - val_loss: 1.3381 - val_accuracy: 0.3606\n",
            "Epoch 19/50\n",
            "433/433 [==============================] - 273s 630ms/step - loss: 1.3277 - accuracy: 0.4238 - val_loss: 1.3247 - val_accuracy: 0.4182\n",
            "Epoch 20/50\n",
            " 74/433 [====>.........................] - ETA: 3:18 - loss: 1.3263 - accuracy: 0.4299"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRowd_cb4Wyn"
      },
      "source": [
        "# saving the model\r\n",
        "model.save(\"VGG_DR_06-01-2021.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjBZHydW4hkt"
      },
      "source": [
        "# display the performance of the model graphically\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "%matplotlib inline\r\n",
        "acc = history.history['accuracy']\r\n",
        "val_acc = history.history['val_accuracy']\r\n",
        "loss = history.history['loss']\r\n",
        "val_loss = history.history['val_loss']\r\n",
        "\r\n",
        "epochs = range(len(acc))\r\n",
        "\r\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\r\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\r\n",
        "plt.title('Training and validation accuracy')\r\n",
        "plt.legend(loc=0)\r\n",
        "plt.figure()\r\n",
        "\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
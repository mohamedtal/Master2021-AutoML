{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "04-01-2021-CNN-DataGenerator.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMCaBm8wDCE12M6Bv1y80Ur",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohamedtal/PFE2021/blob/main/04_01_2021_CNN_DataGenerator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J43LjEzPBEkk",
        "outputId": "806e9951-7c76-459b-80d2-132315d8b552"
      },
      "source": [
        "# before all don't forget to use the GPU\r\n",
        "\r\n",
        "# at first we need to get the dataset from the drive\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WL1HQdpZB7mN"
      },
      "source": [
        "#unzip the dataset\r\n",
        "!unzip /content/drive/MyDrive/dataset/DR-dataset2015.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GTEDUb3CSHy"
      },
      "source": [
        "# we need to delete samples from class 0 ( there is 25000 images, we are going to take just 7000)\r\n",
        "import random\r\n",
        "import os\r\n",
        "BASE_DIR = \"DR-dataset/train/0\"\r\n",
        "NEW_DIR= \"corbeille\"\r\n",
        "\r\n",
        "list_dir =  os.listdir(BASE_DIR)\r\n",
        "to_val = random.sample(list_dir, len(list_dir) - 7000)\r\n",
        "for images in to_val:\r\n",
        "    os.rename(BASE_DIR + \"/\"+ images, NEW_DIR + \"/\" + images )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RU9Cw_9fCveb"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4N3xW0XNCw8w"
      },
      "source": [
        "\r\n",
        "# the train generator with data augmentation and preprocessing (rescale)\r\n",
        "# https://keras.io/api/preprocessing/image/\r\n",
        "# https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator\r\n",
        "train_datagen = ImageDataGenerator(\r\n",
        "    rescale=1./255,\r\n",
        "    shear_range=0.2,\r\n",
        "    zoom_range=0.2,\r\n",
        "    horizontal_flip=True,\r\n",
        "    validation_split=0.15)\r\n",
        "\r\n",
        "\r\n",
        "train_generator = train_datagen.flow_from_directory(\r\n",
        "    'DR-dataset/train',\r\n",
        "    target_size=(224, 224),\r\n",
        "    batch_size=32,\r\n",
        "    class_mode='None')\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFpo3pg5EsGW"
      },
      "source": [
        "model.fit_generator(\r\n",
        "    train_generator,\r\n",
        "    steps_per_epoch=2000,\r\n",
        "    epochs=50,\r\n",
        "    validation_steps=800)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XY5fsQlmfqg"
      },
      "source": [
        "def build_resnet50(num_classes, img_size):\r\n",
        "    from tensorflow.python.keras.applications import ResNet50\r\n",
        "    from tensorflow.python.keras import Model\r\n",
        "    from tensorflow.python.keras.layers import Dense, Flatten\r\n",
        "    resnet = ResNet50(weights='imagenet', include_top=False, input_shape=img_size)\r\n",
        "    x = Flatten(input_shape=resnet.output.shape)(resnet.output)\r\n",
        "    x = Dense(1024, activation='sigmoid')(x)\r\n",
        "    predictions = Dense(num_classes, activation='softmax', name='pred')(x)\r\n",
        "    model = Model(inputs=[resnet.input], outputs=[predictions])\r\n",
        "    return model\r\n",
        "\r\n",
        "\r\n",
        "def build_vgg19(num_classes, img_size):\r\n",
        "    from tensorflow.python.keras.applications import VGG19\r\n",
        "    from tensorflow.python.keras import Model\r\n",
        "    from tensorflow.python.keras.layers import Dense, Flatten\r\n",
        "    vgg19 = VGG19(weights='imagenet', include_top=False, input_shape=img_size)\r\n",
        "    # customize last layers\r\n",
        "    x = Flatten(input_shape=vgg19.output.shape)(vgg19.output)\r\n",
        "    x = Dense(1024, activation='sigmoid')(x)\r\n",
        "    predictions = Dense(num_classes, activation='softmax', name='pred')(x)\r\n",
        "    model = Model(inputs=[vgg19.input], outputs=[predictions])\r\n",
        "    # freeze the first 8 layers\r\n",
        "    for layer in model.layers[:8]:\r\n",
        "        layer.trainable = False\r\n",
        "    return model\r\n",
        "\r\n",
        "\r\n",
        "def build_lenet5(num_classes, img_size):\r\n",
        "    from tensorflow.python.keras import Sequential\r\n",
        "    from tensorflow.python.keras.layers import Conv2D, AveragePooling2D, Flatten, Dense\r\n",
        "    model = Sequential()\r\n",
        "    model.add(Conv2D(filters=6, kernel_size=(3, 3), activation='relu', input_shape=img_size))\r\n",
        "    model.add(AveragePooling2D())\r\n",
        "    model.add(Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))\r\n",
        "    model.add(AveragePooling2D())\r\n",
        "    model.add(Flatten())\r\n",
        "    model.add(Dense(120, activation='relu'))\r\n",
        "    model.add(Dense(84, activation='relu'))\r\n",
        "    model.add(Dense(num_classes, activation='softmax'))\r\n",
        "    return model\r\n",
        "\r\n",
        "\r\n",
        "def build_alexnet(num_classes, img_size):\r\n",
        "    \"\"\"\r\n",
        "    Build an AlexNet\r\n",
        "    :param num_classes: number of classes\r\n",
        "    :param img_size: image size as tuple (width, height, 3) for rgb and (widht, height) for grayscale\r\n",
        "    :return: model\r\n",
        "    \"\"\"\r\n",
        "    from tensorflow.python.keras import Sequential\r\n",
        "    from tensorflow.python.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\r\n",
        "    model = Sequential()\r\n",
        "    model.add(Conv2D(32, (3, 3), padding='same',\r\n",
        "                     input_shape=img_size,\r\n",
        "                     activation='relu'))\r\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu'))\r\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\r\n",
        "    model.add(Dropout(0.2))\r\n",
        "    model.add(Conv2D(64, (3, 3), padding='same',\r\n",
        "                     activation='relu'))\r\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu'))\r\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\r\n",
        "    model.add(Dropout(0.2))\r\n",
        "    model.add(Conv2D(128, (3, 3), padding='same',\r\n",
        "                     activation='relu'))\r\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu'))\r\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\r\n",
        "    model.add(Dropout(0.2))\r\n",
        "    model.add(Flatten())\r\n",
        "    model.add(Dense(512, activation='relu'))\r\n",
        "    model.add(Dropout(0.5))\r\n",
        "    model.add(Dense(num_classes, activation='softmax'))\r\n",
        "    return model\r\n",
        "\r\n",
        "\r\n",
        "def build_cnn1(num_classes, img_size):\r\n",
        "    from tensorflow.keras.models import Sequential\r\n",
        "    from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout\r\n",
        "    import numpy as np \r\n",
        "    model = Sequential()\r\n",
        "    model.add(Conv2D(100, (3, 3), padding='same',\r\n",
        "                     input_shape=img_size,\r\n",
        "                     activation='relu'))\r\n",
        "    model.add(MaxPool2D(pool_size=(2, 2)))\r\n",
        "    model.add(Conv2D(filters=150, kernel_size=(4,4), activation='relu'))\r\n",
        "    model.add(MaxPool2D(pool_size=(2, 2)))\r\n",
        "    model.add(Dropout(rate=0.5))\r\n",
        "    model.add(Conv2D(filters=250, kernel_size=(3, 3), activation='relu'))\r\n",
        "    model.add(MaxPool2D(pool_size=(2, 2)))\r\n",
        "    model.add(Dropout(rate=0.5))\r\n",
        "    model.add(Flatten())\r\n",
        "    model.add(Dense(200, activation='relu'))\r\n",
        "    model.add(Dense(num_classes, activation='softmax'))\r\n",
        "    return model\r\n",
        "\r\n",
        "def build_cnn2(num_classes, img_size):\r\n",
        "    from tensorflow.keras.models import Sequential\r\n",
        "    from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout\r\n",
        "    from tensorflow.keras.regularizers import l2\r\n",
        "    import numpy as np \r\n",
        "    model = Sequential()\r\n",
        "    model.add(Conv2D(32, (5, 5), padding='same',\r\n",
        "                     input_shape=img_size,\r\n",
        "                     activation='relu'))\r\n",
        "    model.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu'))\r\n",
        "    model.add(MaxPool2D(pool_size=(2, 2)))\r\n",
        "    model.add(Dropout(rate=0.5))\r\n",
        "    model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\r\n",
        "    model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\r\n",
        "    model.add(MaxPool2D(pool_size=(2, 2)))\r\n",
        "    model.add(Dropout(rate=0.5))#25\r\n",
        "    model.add(Flatten())\r\n",
        "    model.add(Dense(256, activation='relu'))\r\n",
        "    model.add(Dense(num_classes, activation='softmax'))\r\n",
        "    return model\r\n",
        "\r\n",
        "def build_vgg16(num_classes, img_size):\r\n",
        "    from tensorflow.python.keras.applications import VGG16\r\n",
        "    from tensorflow.python.keras import Model\r\n",
        "    from tensorflow.python.keras.layers import Dense, Flatten\r\n",
        "    vgg16 = VGG16(weights='imagenet', include_top=False, input_shape=img_size)\r\n",
        "    x = Flatten(input_shape=vgg16.output.shape)(vgg16.output)\r\n",
        "    x = Dense(1024, activation='sigmoid')(x)\r\n",
        "    predictions = Dense(num_classes, activation='softmax', name='pred')(x)\r\n",
        "    model = Model(inputs=[vgg16.input], outputs=[predictions])\r\n",
        "    for layer in model.layers[:8]:\r\n",
        "        layer.trainable = False\r\n",
        "    return model\r\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}